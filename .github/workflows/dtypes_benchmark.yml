name: Data Types Benchmark

on:
  push:
    branches:
      - main
    workflow_dispatch:  # Enables manual triggering

jobs:
  run_dtypes_benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install invoke .[test]

      - name: Create folder and JSON file
        run: |
          mkdir -p results
          touch results/${{ matrix.python-version }}.json

      # Run the benchmarking
      - name: Benchmark Data Types
        env:
          PYDRIVE_CREDENTIALS: ${{ secrets.PYDRIVE_CREDENTIALS }}
        run: |
          invoke benchmark-dtypes

        continue-on-error: true

      # Upload the json files as artifacts
      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: results-${{ matrix.python-version }}
          path: results/*.json

  generate_dtypes_report:
    runs-on: ubuntu-latest
    needs: run_dtypes_benchmark

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Set up Python 3.10
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies for report
        run: |
          python -m pip install --upgrade pip
          python -m pip install .[test]

      # Download the artifacts
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          path: results/

      # Generate the report
      - name: Generate the report
        env:
          PYDRIVE_CREDENTIALS: ${{ secrets.PYDRIVE_CREDENTIALS }}
          SLACK_TOKEN: ${{ secrets.SLACK_TOKEN }}
          # Conditionally set TEST_OUTPUT_FOLDER if workflow_dispatch triggered the run
          TEST_OUTPUT_FOLDER: ${{ github.event_name == 'workflow_dispatch' && '1tjre6vNnbAv6jyfsF8N8EZfDX7Rx2HCT' || '' }}

        run: python -m tests.benchmark.utils
